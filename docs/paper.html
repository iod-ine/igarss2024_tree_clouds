<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.554">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>An exploration of properties of point clouds of individual trees extracted from a larger UAV LiDAR survey</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="paper_files/libs/clipboard/clipboard.min.js"></script>
<script src="paper_files/libs/quarto-html/quarto.js"></script>
<script src="paper_files/libs/quarto-html/popper.min.js"></script>
<script src="paper_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="paper_files/libs/quarto-html/anchor.min.js"></script>
<link href="paper_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="paper_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="paper_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="paper_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="paper_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>


</head>

<body class="fullcontent">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><p>An exploration of properties of point clouds of individual trees extracted from a larger UAV LiDAR survey</p></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  
<div>
  <div class="abstract">
    <div class="block-title">Abstract</div>
    <p>This study aims to explore the properties of point clouds of individual trees manually extracted from a large UAV LiDAR survey over a dense mixed forest. The dataset contains 192 trees of seven species, with an approximately even mix of deciduous and coniferous trees, which proves to be very limiting. Two experiments are described. The first is aimed at setting up an approach to help gain intuition about manual features used in classical machine learning on point clouds. Example visualizations are provided to demonstrate the effectiveness. The second is aimed at assessing the viability of approximating average tree shapes by estimating the kernel density of three-dimensional distributions of point coordinates. It shows relatively good overall accuracy in binary classification, but is unreliable in the multiclass setting and too slow. The dataset and the code are freely accessible through Kaggle.</p>
  </div>
</div>


</header>


<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>The demand for detailed forest inventories is growing, fueled by the need for quality data for harvest and afforestation planning, sustainable forest management and conservation, modeling of carbon stock and carbon cycles, and more. The increasing accessibility of UAVs and LiDAR sensors makes UAV LiDAR an ever more valuable tool for conducting such inventories. The technical characteristics of modern sensors alalow for very dense measurements, which in turn introduce a shift from the area-based approach <span class="citation" data-cites="whiteABAGuide2013">(<a href="#ref-whiteABAGuide2013" role="doc-biblioref">White 2013</a>)</span> dominating early research and applications of LiDAR in forestry and still widely used in the industry to an individual tree-based approach. This shift brings the requirement for algorithms for automatic detection and segmentation of individual trees within larger point clouds. This problem can be solved well for forest stands that are either predominantly coniferous or sparse, even by simple local maxima detection algorithms on rasterized point clouds <span class="citation" data-cites="eysnAlpineITDBenchmark2015">(<a href="#ref-eysnAlpineITDBenchmark2015" role="doc-biblioref">Eysn et al. 2015</a>)</span>. However, it remains an open challenge to develop a universal, robust detection approach for dense mixed forests, in which the canopy structure is complex. There is a growing body of research on developing and applying more complex and precise methods, but most results that can be considered successful from the industrial adoption point of view are in more mild forest types <span class="citation" data-cites="balsiSingletreeDetectionHighdensity2018">Jeronimo et al. (<a href="#ref-jeronimoApplyingLiDARIndividual2018" role="doc-biblioref">2018</a>)</span>.</p>
<p>In this study, we try to gain insight into the problem of tree detection and segmentation by looking at its expected output. We analyze a collection of individual trees manually identified in the large survey data over a dense mixed forest and explore their features and properties.</p>
</section>
<section id="materials-and-methods" class="level1">
<h1>Materials and methods</h1>
<p>The dataset for this study was created by manually extracting individual trees from a large UAV LiDAR survey over a dense mixed forest. The original point cloud was preprocessed by removing duplicates and noise, classifying the ground points, and normalizing the height. The dataset contains 192 point clouds of individual trees with a mix of coniferous and deciduous species. <a href="#fig-species-count" class="quarto-xref">Figure&nbsp;1</a> shows the distribution of species in the dataset, and <a href="#fig-visualization" class="quarto-xref">Figure&nbsp;2</a> shows two visualizations of samples from the dataset: a cross-section of a tree of every species constructed by ignoring the Y coordinate, and a single spruce in 3D. Because the observations are made from above, many trees have the highest concentrations of points at the top of their canopy and a very limited number of points along the trunk. Additionally, slight slopes of the terrain manifest as artificial tilt in some of the trees because of the height normalization of the original point cloud.</p>
<div id="cell-fig-species-count" class="cell" data-execution_count="3">
<div class="cell-output cell-output-display">
<div id="fig-species-count" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-species-count-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="paper_files/figure-html/fig-species-count-output-1.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-species-count-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Distribution of tree species in the dataset. It contains 192 point clouds of individual trees: 101 coniferous and 91 deciduous.
</figcaption>
</figure>
</div>
</div>
</div>
<p>The first experiment we report in this manuscript aims to build intuition into commonly used features for classical machine learning on point clouds. We set up the experiment as a classification problem with two settings: a binary one, in which the target is the type of tree, coniferous or deciduous, and a multiclass one, in which the target is the species directly. The features we use include point height distribution features from <span class="citation" data-cites="woodsPredictingForestStand2008">(<a href="#ref-woodsPredictingForestStand2008" role="doc-biblioref">Woods, Lim, and Treitz 2008</a>)</span> and shape features from <span class="citation" data-cites="lucasIdentificationLinearVegetation2019">(<a href="#ref-lucasIdentificationLinearVegetation2019" role="doc-biblioref">Lucas et al. 2019</a>)</span> derived from the eigenvalues of the covariance matrix of the coordinates. We calculate each feature for the entire point cloud and use a 2% threshold for height to remove ground points from the calculation, since we find they serve only as noise. To verify that the features are meaningful and assess which are more important, we then fit a logistic regression model on standardized feature values and look at its 10-fold stratified cross-validation accuracy scores and feature coefficients. Finally, we arrange each individual tree within its species group by the value of a feature of interest and plot multiple samples from each end of the feature range. This allows us to associate features and their possible values with the actual shapes of trees.</p>
<div class="cell" data-layout="[[2.5,1]]" data-execution_count="4">
<div id="fig-visualization" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-visualization-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="cell-output cell-output-display quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-visualization" style="flex-basis: 71.4%;justify-content: flex-start;">
<div id="fig-visualization-1" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-visualization-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="paper_files/figure-html/fig-visualization-output-1.png" class="img-fluid figure-img" data-ref-parent="fig-visualization">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-visualization-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(a) Cross-sections of random trees of every species (ignoring the Y dimension).
</figcaption>
</figure>
</div>
</div>
<div class="cell-output cell-output-display quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-visualization" style="flex-basis: 28.6%;justify-content: flex-start;">
<div id="fig-visualization-2" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-visualization-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="paper_files/figure-html/fig-visualization-output-2.png" class="img-fluid figure-img" data-ref-parent="fig-visualization">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-visualization-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(b) A spruce in 3D.
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-visualization-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: Visualizations of the individual tree point clouds in the dataset. Most of the tree clouds are top-heavy because of the observation from above, and some are artificially tilted because of slight terrain slopes and height normalization. The ground points are present.
</figcaption>
</figure>
</div>
</div>
<p>The second experiment is also set up as a multiclass classification problem. Instead of encoding the shape of the point cloud through features based on distributions of heights and eigenvalues of the covariance matrix, we treat the whole tree cloud as a three-dimensional distribution. First, we construct super-trees for each species by merging multiple scaled and centered point clouds into one. Figure <a href="#fig-super-trees" class="quarto-xref">Figure&nbsp;3</a>} shows examples of such super-trees for birch and fir, visualized as a scatter plot with very low alpha and as a hex 2D histogram. Then, each super-tree is used to fit a kernel density estimator by treating each point as a three-dimensional observation. They can then be used to estimate the likelihood of individual trees belonging to the same distribution as each of the super-trees.</p>
<div id="cell-fig-super-trees" class="cell" data-execution_count="5">
<div class="cell-output cell-output-display">
<div id="fig-super-trees" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-super-trees-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="paper_files/figure-html/fig-super-trees-output-1.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-super-trees-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: Super-trees for birch and fir as a scatter plot with very low alpha and as a hex 2D histogram. A super-tree for a species is a collection of tree clouds of that species centered, scaled, and merged into one.
</figcaption>
</figure>
</div>
</div>
</div>
<p>We make the data and code used in this study available through Kaggle <span class="citation" data-cites="dubrovinIndividualTreesUAV2023">(<a href="#ref-dubrovinIndividualTreesUAV2023" role="doc-biblioref">Dubrovin and Kedrov 2023</a>)</span>. The notebooks there contain additional visualizations and experiments and are easy to copy, run, and modify in pinned environments without installing anything locally. We only report two experiments here due to limitations on the length of the manuscript.</p>
</section>
<section id="results-and-discussion" class="level1">
<h1>Results and discussion</h1>
<p>An obvious limitation of this study is the size of the dataset. A sample of 192 examples is hardly enough to run reliable experiments without investing significant effort to avoid overfitting. It also severely limits how tight the error bars on quantitative estimates can be. With that limitation in mind, below we present the results of the reported experiments and invite the reader to visit the Kaggle page that hosts the dataset to look at more detailed results and visualizations.</p>
<p>Table <a href="#tbl-accuracy-1" class="quarto-xref">Table&nbsp;1</a> reports the 10-fold stratified cross-validation accuracies of the logistic regression in both settings of the first experiment. In both settings, the model performs reasonably well, and the results are predictably much better in the simpler binary setting. The absolute values of the fitted coefficients, which we use to estimate the importance of features, are dominated by features based on the height distribution of points. Features based on the eigenvalues of the covariance matrix have very little effect on the overall prediction because all the point clouds in the dataset are very similar in shape. The heights of the trees are almost an order of magnitude larger than their widths, making one of the eigenvalues significantly larger than the rest and making all features based on them have very similar values. A notable exception is the omnivariance, calculated as the cube root of the product of all three eigenvalues and consistently ending up at the top of the coefficient magnitudes. Figure <a href="#fig-feature-ranges" class="quarto-xref">Figure&nbsp;4</a> presents visualizations that are the target of the first experiment, using spruce and aspen and omnivariance and percent of points higher than mean height as examples. Based on the visualization, we can see how larger values of omnivariance correspond to spruce tree clouds that are more evenly spread out in all directions, being more elliptical than linear, and how lower values of percent of points higher than mean height correspond to bushier, top-heavy aspen tree clouds.</p>
<div class="cell" data-jupyter="{&quot;source_hidden&quot;:true}" data-layout-nrow="2" data-execution_count="7">
<div id="fig-feature-ranges" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-feature-ranges-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="cell-output cell-output-display quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-feature-ranges" style="flex-basis: 100.0%;justify-content: flex-start;">
<div id="fig-feature-ranges-1" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-feature-ranges-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="paper_files/figure-html/fig-feature-ranges-output-1.png" class="img-fluid figure-img" data-ref-parent="fig-feature-ranges">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-feature-ranges-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(a) Effect of omnivariance on the shape of spruce.
</figcaption>
</figure>
</div>
</div>
</div>
<div class="quarto-layout-row">
<div class="cell-output cell-output-display quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-feature-ranges" style="flex-basis: 100.0%;justify-content: flex-start;">
<div id="fig-feature-ranges-2" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-feature-ranges-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="paper_files/figure-html/fig-feature-ranges-output-2.png" class="img-fluid figure-img" data-ref-parent="fig-feature-ranges">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-feature-ranges-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(b) Effect of percent of points higher than mean height on the shape of aspen.
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-feature-ranges-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4: Example visualizations of the shapes of individual trees on different ends of ranges of commonly used features in classical machine learning on point clouds.
</figcaption>
</figure>
</div>
</div>
<div class="cell" data-jupyter="{&quot;source_hidden&quot;:true}" data-execution_count="9">
<div id="tbl-accuracy-1" class="cell quarto-float anchored" data-jupyter="{&quot;source_hidden&quot;:true}" data-execution_count="9">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-accuracy-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;1: 10-fold stratified cross-validation accuracy for the logistic regression in binary and multiclass settings.
</figcaption>
<div aria-describedby="tbl-accuracy-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output cell-output-display" data-execution_count="9">
<div>
<div>


<table class="dataframe do-not-create-environment cell table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">CV accuracy</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">Binary</td>
<td>0.927 ± 0.042</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">Multiclass</td>
<td>0.777 ± 0.042</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</div>
</figure>
</div>
</div>
<p>The metrics for the second experiment were calculated on a 40% hold-out set obtained from the entire dataset by stratified sampling and are shown in table <a href="#tbl-accuracy-2" class="quarto-xref">Table&nbsp;2</a>. The confusion matrices for both settings are shown in Figure <a href="#fig-confusion" class="quarto-xref">Figure&nbsp;5</a>. Once again, the results in the binary setting are significantly better than in the multiclass one, which is to be expected, especially with such a small overall sample size and a relatively large number of classes. Per-species metrics are all over the place: out of the 8 pines in the hold-out set, every one was classified correctly, and at the same time, not a single one of the 7 tilia was. Despite the overall performance in the multiclass setting being very low and chaotic, it’s still significantly better than random, which leads us to believe that the quality can be improved on larger samples. It is, however, important to note that the approach of estimating 3D kernel density for each species takes too long during the inference phase, despite being relatively easy to set up and apply and showing reasonable quality in the binary setting.</p>
<div id="fig-confusion" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-confusion-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="cell-output cell-output-display quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-confusion" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-confusion-1" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-confusion-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="paper_files/figure-html/fig-confusion-output-1.png" class="img-fluid figure-img" data-ref-parent="fig-confusion">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-confusion-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(a) Binary setting: predicting conifers vs.&nbsp;deciduous trees
</figcaption>
</figure>
</div>
</div>
<div class="cell-output cell-output-display quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-confusion" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-confusion-2" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-confusion-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="paper_files/figure-html/fig-confusion-output-2.png" class="img-fluid figure-img" data-ref-parent="fig-confusion">
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-confusion-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(b) Multiclass setting: predicting the species directly.
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-confusion-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5: Confusion matrices for prediction of tree species by calculating the log-likelihood of its tree cloud points being from the distribution estimated on the corresponding super-tree.
</figcaption>
</figure>
</div>
<div class="cell" data-execution_count="14">
<div id="tbl-accuracy-2" class="cell quarto-float anchored" data-execution_count="14">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-accuracy-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;2: Hold-out set accuracy for the second experiment. The hold-out set is a 40% stratified sample from the entire dataset.
</figcaption>
<div aria-describedby="tbl-accuracy-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output cell-output-display" data-execution_count="14">
<div>
<div>


<table class="dataframe do-not-create-environment cell table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Accuracy</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">Binary: Overall</td>
<td>0.857</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">Binary: Coniferous</td>
<td>0.927</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">Binary: Deciduous</td>
<td>0.778</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">Multiclass: Overall</td>
<td>0.506</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">Multiclass: Coniferous</td>
<td>0.512</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">Multiclass: Deciduous</td>
<td>0.500</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</div>
</figure>
</div>
</div>
</section>
<section id="conclusions" class="level1">
<h1>Conclusions</h1>
<p>This manuscript offers an overview of a study aimed at exploring the properties of point clouds of individual trees and searching for insight into the complex open problem of individual tree detection in large point clouds. We report two experiments, the first of which is set up to explore how commonly used features in classical machine learning on point clouds manifest in the shapes of actual individual trees, and the second – to test the validity of approximating the shapes of trees by fitting a kernel density estimator on super-trees of different species. We show an example of how arranging visualizations of tree clouds based on the value of a feature can be used to gain intuition on what that feature represents in the real world. We also show how a super-tree can be used to estimate a kernel density function and how that function can be used to predict whether a tree cloud belongs to a specific species. This ends up being relatively straightforward to set up but results in very slow inference and subpar quality, at least at this sample size. Both of the approaches described can be adapted to segmentation and detection in large point clouds by applying the classification algorithms in windows.</p>
</section>
<section id="acknowledgements" class="level1">
<h1>Acknowledgements</h1>
<p>All data was collected and processed by Space technologies and services center, Ltd, Perm, Russia and published with their permission.</p>

</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-balsiSingletreeDetectionHighdensity2018" class="csl-entry" role="listitem">
Balsi, M., S. Esposito, P. Fallavollita, and C. Nardinocchi. 2018. <span>“Single-Tree Detection in High-Density <span>LiDAR</span> Data from <span class="nocase">UAV-based</span> Survey.”</span> <em>European Journal of Remote Sensing</em> 51 (1): 679–92. <a href="https://doi.org/10.1080/22797254.2018.1474722">https://doi.org/10.1080/22797254.2018.1474722</a>.
</div>
<div id="ref-dubrovinIndividualTreesUAV2023" class="csl-entry" role="listitem">
Dubrovin, Ivan, and Aleksandr Kedrov. 2023. <span>“Individual Trees in <span>UAV LiDAR</span> Point Clouds.”</span> <a href="https://www.kaggle.com/ds/4198515" class="uri">https://www.kaggle.com/ds/4198515</a>; <span>Kaggle</span>. <a href="https://doi.org/10.34740/KAGGLE/DS/4198515">https://doi.org/10.34740/KAGGLE/DS/4198515</a>.
</div>
<div id="ref-eysnAlpineITDBenchmark2015" class="csl-entry" role="listitem">
Eysn, Lothar, Markus Hollaus, Eva Lindberg, Frédéric Berger, Jean-Matthieu Monnet, Michele Dalponte, Milan Kobal, et al. 2015. <span>“A <span>Benchmark</span> of <span>Lidar-Based Single Tree Detection Methods Using Heterogeneous Forest Data</span> from the <span>Alpine Space</span>.”</span> <em>Forests</em> 6 (5): 1721–47. <a href="https://doi.org/10.3390/f6051721">https://doi.org/10.3390/f6051721</a>.
</div>
<div id="ref-jeronimoApplyingLiDARIndividual2018" class="csl-entry" role="listitem">
Jeronimo, Sean M A, Van R Kane, Derek J Churchill, Robert J McGaughey, and Jerry F Franklin. 2018. <span>“Applying <span>LiDAR Individual Tree Detection</span> to <span>Management</span> of <span>Structurally Diverse Forest Landscapes</span>.”</span> <em>Journal of Forestry</em> 116 (4): 336–46. <a href="https://doi.org/10.1093/jofore/fvy023">https://doi.org/10.1093/jofore/fvy023</a>.
</div>
<div id="ref-lucasIdentificationLinearVegetation2019" class="csl-entry" role="listitem">
Lucas, Chris, Willem Bouten, Zsófia Koma, W. Daniel Kissling, and Arie C. Seijmonsbergen. 2019. <span>“Identification of <span>Linear Vegetation Elements</span> in a <span>Rural Landscape Using LiDAR Point Clouds</span>.”</span> <em>Remote Sensing</em> 11 (3, 3): 292. <a href="https://doi.org/10.3390/rs11030292">https://doi.org/10.3390/rs11030292</a>.
</div>
<div id="ref-whiteABAGuide2013" class="csl-entry" role="listitem">
White, Joanne. 2013. <em>A Best Practices Guide for Generating Forest Inventory Attributes from Airborne Laser Scanning Data Using the Area-Based Approach</em>. <span>Victoria, British Columbia</span>: <span>Canadian Forest Service</span>.
</div>
<div id="ref-woodsPredictingForestStand2008" class="csl-entry" role="listitem">
Woods, M., K. Lim, and P. Treitz. 2008. <span>“Predicting Forest Stand Variables from <span>LiDAR</span> Data in the <span>Great Lakes</span> – <span>St</span>. <span>Lawrence</span> Forest of <span>Ontario</span>.”</span> <em>The Forestry Chronicle</em> 84 (6): 827–39. <a href="https://doi.org/10.5558/tfc84827-6">https://doi.org/10.5558/tfc84827-6</a>.
</div>
</div></section></div></main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>